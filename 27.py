# -*- coding: utf-8 -*-
"""27.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R03HmgH0Ui22EeVhy3_QhsuDdJDJ4UTl
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/Admission_Predict.csv')
df

"""Perform the following operations using Python on Graduate admission dataset.

u. Check for duplicate rows and remove it

v. Plot heat map for the continuous data.

w. Check for null /Nan values and replace them with appropriate values.

x. Consider the column with highest correlation in the dataset to build linear regression model to predict chance of admit.

"""

df.isnull().sum()

df.dtypes

df['Research'] = df['Research'].astype('float64')
df['Serial No.'] = df['Serial No.'].astype('float64')
df['GRE Score'] = df['GRE Score'].astype('float64')
df['University Rating'] = df['University Rating'].astype('float64')
df['TOEFL Score'] = df['TOEFL Score'].astype('float64')

df.dtypes

df.duplicated().sum()

#drop_duplicates = df.drop_duplicates()
#drop_duplicates

df.isnull().sum()

# df['share'].value_counts()

'''
14.0     20
13.0     20
26.0     16
10.0     16
17.0     15
         ..
84.0      1
63.0      1
72.0      1
147.0     1
46.0      1
Name: share, Length: 88, dtype: int64
'''

# mean = df['share'].mean()
# df['share'].fillna(mean, inplace = True)

"""v. Plot heat map for the continuous data."""

# Compute the correlation matrix
corr_matrix = df.corr()

# Plot the heatmap
sns.heatmap(corr_matrix, cmap='coolwarm', annot=True)

# Add plot title
plt.title('Correlation Heatmap')

# Display the plot
plt.show()

"""x. Consider the column with highest correlation in the dataset to build linear regression model to predict chance of admit."""

df.columns

X = df[['CGPA']].values
y = df['Chance of Admit ']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=123)

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_prediction = lr.predict(X_test)

from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_prediction)
rmse = np.sqrt(mse)

print("Mean square error: ", mse)
print("Rmse: ", rmse)

plt.scatter(X_test, y_test, color='blue', label="Data")
plt.plot(X_test, y_prediction, color='red', label='Linear Regression Line')

plt.xlabel('CGPA')
plt.ylabel('Chance of Admit')
plt.title('Linear Regression')

plt.legend()

plt.show()

"""Perform the following operations using Python on Graduate admission dataset.

u. Check for duplicate rows and remove it

v. Plot heat map for the continuous data.

w. Check for null /Nan values and replace them with appropriate values.

x. Consider the column with highest correlation in the dataset to build linear regression model to predict chance of admit.
"""



"""Perform the following operations using Python on Graduate admission Dataset.
g. Create data subsets by making classes for Chances of admit.(e.g. Not Admitted,
might get admitted, Admitted).

h. Merge two subsets

i. Sort Data using GRE, TOEFL and University rating.

j. Transposing Data

k. Melting Data to long format
 
l.Casting data to wide format

"""

df

df.columns

df['Chance of Admit '].value_counts

lower_bound = 0.8
upper_bound = 1.0

mask = (df['Chance of Admit '] >= lower_bound ) & (df['Chance of Admit '] <= upper_bound)
subset1 = df.loc[mask, :]
subset1

mask = (df['Chance of Admit '] >= 0.5 ) & (df['Chance of Admit '] <= 0.7)
subset2 = df.loc[mask, :]
subset2

mask = (df['Chance of Admit '] < 0.4 )
subset3 = df.loc[mask, :]
subset3

for rows in subset1['Chance of Admit '].values:
    subset1.replace(rows, 'Admitted', inplace =True)
subset1

for rows in subset2['Chance of Admit '].values:
    subset2.replace(rows, 'Might get Aadmitted', inplace =True)
subset2

for rows in subset3['Chance of Admit '].values:
    subset3.replace(rows, 'Not Aadmitted', inplace =True)
subset3

merge = pd.concat([subset1, subset2, subset3], axis=0)
merge

merge.columns

sort =  merge.sort_values(by=['GRE Score', 'TOEFL Score', 'University Rating'], ascending=False)
sort

transpose = sort.transpose()
transpose

sort.columns

sort.dtypes

melt = sort.melt(id_vars=['Serial No.', 'University Rating', 'SOP',
       'LOR ', 'CGPA', 'Research', 'Chance of Admit ' ], var_name="exams", value_name="score")
melt

select = pd.DataFrame(df, columns=['Research', 'Chance of Admit ', 'University Rating', 'SOP'])
select

cast = pd.pivot_table(select, index=['Research','University Rating', 'SOP'])
cast

