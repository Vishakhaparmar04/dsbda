# -*- coding: utf-8 -*-
"""ps15.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DD4VjQcc3kin4k_NGcD2zaglOswO4CEq
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns

!unzip /content/breast_cancer.zip

df = pd.read_csv("/content/adult.csv")

df

df.isnull().sum()

df= df.dropna()
df

df['salary'].value_counts()

df['salary'] = df['salary'].replace(' <=50K', '0')
# df['column2'] = df['column2'].replace({'old_value': 'new_value'})

df['salary'] = df['salary'].replace(' >50K', '1')
# df['column2'] = df['column2'].replace({'old_value': 'new_value'})

df['salary']

df.columns



df.head()

df.shape

df.columns

count_features = ['age', 'education-num',
       'capital-gain', 'capital-loss', 'hours-per-week']

# continous_features = ['age','trestbps','chol','thalach','oldpeak'] 
def outliers(df_out, drop = False):
  for each_feature in df_out.columns:
      feature_data = df_out[each_feature]
      Q1 = np.percentile(feature_data, 25.) # 25th percentile of the data of the given feature
      Q3 = np.percentile(feature_data, 75.) # 75th percentile of the data of the given feature
      IQR = Q3-Q1 #Interquartile Range
      outlier_step = IQR * 1.5 #That's we were talking about above
      outliers = feature_data[~((feature_data >= Q1 - outlier_step) & 
      (feature_data <= Q3 + outlier_step))].index.tolist() 
      if not drop:
        print('For the feature {}, No of Outliers is {}'.format(each_feature, len(outliers)))
      if drop:
        df.drop(outliers, inplace = True, errors = 'ignore')
        print('Outliers from {} feature removed'.format(each_feature))

outliers(df[count_features])

outliers(df[count_features], drop=True)

df

duplicated = df.duplicated().sum()

duplicated

df = df.drop_duplicates()

df.shape

df

df.dtypes

from sklearn.preprocessing import LabelEncoder
labelencoder=LabelEncoder()
df["workclass"]=labelencoder.fit_transform(df["workclass"])
df["education"]=labelencoder.fit_transform(df["education"])
df["maritial-status"]=labelencoder.fit_transform(df["maritial-status"])
df["occupation"]=labelencoder.fit_transform(df["occupation"])
df["relationship"]=labelencoder.fit_transform(df["relationship"])
df["race"]=labelencoder.fit_transform(df["race"])
df["sex"]=labelencoder.fit_transform(df["sex"])
df["native-country"]=labelencoder.fit_transform(df["native-country"])
df["salary"]=labelencoder.fit_transform(df["salary"])

df

from sklearn.naive_bayes import MultinomialNB
multinomial = MultinomialNB()

X = df.drop(['salary'], axis=1).values
y = df['salary']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=123)

multinomial.fit(X_train, y_train)
y_pred = multinomial.predict(X_test)

from sklearn import metrics
print("1. Accuracy Score:", metrics.accuracy_score(y_test, y_pred)*100)
print("2. Precision Score:",metrics.precision_score(y_test, y_pred))
print("3. Recall Score:", metrics.recall_score(y_test, y_pred))
print("4. f1 Score:", metrics.f1_score(y_test, y_pred))

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)
y_prediction = model.predict(X_test)

# from sklearn import metrics
print("1. Accuracy Score:", metrics.accuracy_score(y_test, y_prediction)*100)
print("2. Precision Score:",metrics.precision_score(y_test, y_prediction))
print("3. Recall Score:", metrics.recall_score(y_test, y_prediction))
print("4. f1 Score:", metrics.f1_score(y_test, y_prediction))



